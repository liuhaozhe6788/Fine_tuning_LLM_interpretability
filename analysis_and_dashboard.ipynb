{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981069ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, Union\n",
    "from huggingface_hub import hf_hub_download, login\n",
    "import json\n",
    "import einops\n",
    "import os\n",
    "from typing import NamedTuple\n",
    "from sae_vis.data_config_classes import SaeVisConfig\n",
    "from nnsight import LanguageModel\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab94660",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42cb523",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LanguageModel('mistralai/Mistral-7B-Instruct-v0.3', device_map='cuda:0', dtype=torch.bfloat16)\n",
    "chat_model = LanguageModel('liuhaozhe6788/mistralai_Mistral-7B-Instruct-v0.3-FinQA-lora', device_map='cuda:0', dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_data():\n",
    "    data = pd.read_csv(\"data/finqa_test_generated_filtered.csv\")\n",
    "    full_text_data = data.apply(lambda x: x[\"prompt\"] + x[\"generated_code\"], axis=1)\n",
    "\n",
    "    all_text_data = full_text_data.tolist()\n",
    "    return all_text_data\n",
    "\n",
    "all_texts = prepare_text_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d35dd0",
   "metadata": {},
   "source": [
    "# Loading the crosscoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f32dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPES = {\"fp32\": torch.float32, \"fp16\": torch.float16, \"bf16\": torch.bfloat16}\n",
    "\n",
    "class LossOutput(NamedTuple):\n",
    "    # loss: torch.Tensor\n",
    "    l2_loss: torch.Tensor\n",
    "    l1_loss: torch.Tensor\n",
    "    l0_loss: torch.Tensor\n",
    "    explained_variance: torch.Tensor\n",
    "    explained_variance_A: torch.Tensor\n",
    "    explained_variance_B: torch.Tensor\n",
    "\n",
    "class CrossCoder_demo(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        d_hidden = self.cfg[\"dict_size\"]\n",
    "        d_in = self.cfg[\"d_in\"]\n",
    "        self.dtype = DTYPES[self.cfg[\"enc_dtype\"]]\n",
    "        torch.manual_seed(self.cfg[\"seed\"])\n",
    "        # hardcoding n_models to 2\n",
    "        self.W_enc = nn.Parameter(\n",
    "            torch.empty(2, d_in, d_hidden, dtype=self.dtype)\n",
    "        )\n",
    "        self.W_dec = nn.Parameter(\n",
    "            torch.nn.init.normal_(\n",
    "                torch.empty(\n",
    "                    d_hidden, 2, d_in, dtype=self.dtype\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        self.W_dec = nn.Parameter(\n",
    "            torch.nn.init.normal_(\n",
    "                torch.empty(\n",
    "                    d_hidden, 2, d_in, dtype=self.dtype\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        # Make norm of W_dec 0.1 for each column, separate per layer\n",
    "        self.W_dec.data = (\n",
    "            self.W_dec.data / self.W_dec.data.norm(dim=-1, keepdim=True) * self.cfg[\"dec_init_norm\"]\n",
    "        )\n",
    "        # Initialise W_enc to be the transpose of W_dec\n",
    "        self.W_enc.data = einops.rearrange(\n",
    "            self.W_dec.data.clone(),\n",
    "            \"d_hidden n_models d_model -> n_models d_model d_hidden\",\n",
    "        )\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_hidden, dtype=self.dtype))\n",
    "        self.b_dec = nn.Parameter(\n",
    "            torch.zeros((2, d_in), dtype=self.dtype)\n",
    "        )\n",
    "        self.d_hidden = d_hidden\n",
    "\n",
    "        self.to(self.cfg[\"device\"])\n",
    "        self.save_dir = None\n",
    "        self.save_version = 0\n",
    "\n",
    "    def encode(self, x, apply_relu=True):\n",
    "        # x: [batch, n_models, d_model]\n",
    "        x_enc = einops.einsum(\n",
    "            x,\n",
    "            self.W_enc,\n",
    "            \"batch n_models d_model, n_models d_model d_hidden -> batch d_hidden\",\n",
    "        )\n",
    "        if apply_relu:\n",
    "            acts = F.relu(x_enc + self.b_enc)\n",
    "        else:\n",
    "            acts = x_enc + self.b_enc\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        # acts: [batch, d_hidden]\n",
    "        acts_dec = einops.einsum(\n",
    "            acts,\n",
    "            self.W_dec,\n",
    "            \"batch d_hidden, d_hidden n_models d_model -> batch n_models d_model\",\n",
    "        )\n",
    "        return acts_dec + self.b_dec\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, n_models, d_model]\n",
    "        acts = self.encode(x)\n",
    "        return self.decode(acts)\n",
    "\n",
    "    def get_losses(self, x):\n",
    "        # x: [batch, n_models, d_model]\n",
    "        x = x.to(self.dtype)\n",
    "        acts = self.encode(x)\n",
    "        # acts: [batch, d_hidden]\n",
    "        x_reconstruct = self.decode(acts)\n",
    "        diff = x_reconstruct.float() - x.float()\n",
    "        squared_diff = diff.pow(2)\n",
    "        l2_per_batch = einops.reduce(squared_diff, 'batch n_models d_model -> batch', 'sum')\n",
    "        l2_loss = l2_per_batch.mean()\n",
    "\n",
    "        total_variance = einops.reduce((x - x.mean(0)).pow(2), 'batch n_models d_model -> batch', 'sum')\n",
    "        explained_variance = 1 - l2_per_batch / total_variance\n",
    "\n",
    "        per_token_l2_loss_A = (x_reconstruct[:, 0, :] - x[:, 0, :]).pow(2).sum(dim=-1).squeeze()\n",
    "        total_variance_A = (x[:, 0, :] - x[:, 0, :].mean(0)).pow(2).sum(-1).squeeze()\n",
    "        explained_variance_A = 1 - per_token_l2_loss_A / total_variance_A\n",
    "\n",
    "        per_token_l2_loss_B = (x_reconstruct[:, 1, :] - x[:, 1, :]).pow(2).sum(dim=-1).squeeze()\n",
    "        total_variance_B = (x[:, 1, :] - x[:, 1, :].mean(0)).pow(2).sum(-1).squeeze()\n",
    "        explained_variance_B = 1 - per_token_l2_loss_B / total_variance_B\n",
    "\n",
    "        decoder_norms = self.W_dec.norm(dim=-1)\n",
    "        # decoder_norms: [d_hidden, n_models]\n",
    "        total_decoder_norm = einops.reduce(decoder_norms, 'd_hidden n_models -> d_hidden', 'sum')\n",
    "        l1_loss = (acts * total_decoder_norm[None, :]).sum(-1).mean(0)\n",
    "\n",
    "        l0_loss = (acts>0).float().sum(-1).mean()\n",
    "\n",
    "        return LossOutput(l2_loss=l2_loss, l1_loss=l1_loss, l0_loss=l0_loss, explained_variance=explained_variance, explained_variance_A=explained_variance_A, explained_variance_B=explained_variance_B)\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_hf(\n",
    "        cls,\n",
    "        repo_id: str = \"liuhaozhe6788/crosscoder-model-diff-mistral-7b-instruct-v0.3_finQA_lora\",\n",
    "        device: Optional[Union[str, torch.device]] = None\n",
    "    ) -> \"CrossCoder_demo\":\n",
    "        \"\"\"\n",
    "        Load CrossCoder_demo weights and config from HuggingFace.\n",
    "\n",
    "        Args:\n",
    "            repo_id: HuggingFace repository ID\n",
    "            path: Path within the repo to the weights/config\n",
    "            model: The transformer model instance needed for initialization\n",
    "            device: Device to load the model to (defaults to cfg device if not specified)\n",
    "\n",
    "        Returns:\n",
    "            Initialized CrossCoder_demo instance\n",
    "        \"\"\"\n",
    "\n",
    "        # Download config and weights\n",
    "        config_path = hf_hub_download(\n",
    "            repo_id=repo_id,\n",
    "            filename=f\"cfg.json\"\n",
    "        )\n",
    "        weights_path = hf_hub_download(\n",
    "            repo_id=repo_id,\n",
    "            filename=f\"model.pt\"\n",
    "        )\n",
    "\n",
    "        # Load config\n",
    "        with open(config_path, 'r') as f:\n",
    "            cfg = json.load(f)\n",
    "\n",
    "        # Override device if specified\n",
    "        if device is not None:\n",
    "            cfg[\"device\"] = str(device)\n",
    "\n",
    "        # Initialize CrossCoder_demo with config\n",
    "        instance = cls(cfg)\n",
    "\n",
    "        # Load weights\n",
    "        state_dict = torch.load(weights_path, map_location=cfg[\"device\"])\n",
    "        instance.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "\n",
    "        return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23980de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_coder = CrossCoder_demo.load_from_hf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03e590",
   "metadata": {},
   "source": [
    "# Replicating Anthropic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = cross_coder.W_dec.norm(dim=-1)\n",
    "norms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_norms = norms[:, 1] / norms.sum(dim=-1)\n",
    "relative_norms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3267d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_norms_np = relative_norms.detach().cpu().numpy()\n",
    "np.argsort(relative_norms_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d435bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    relative_norms.detach().cpu().numpy(),\n",
    "    title=\"Gemma 2 2B Base vs IT Model Diff\",\n",
    "    labels={\"value\": \"Relative decoder norm strength\"},\n",
    "    nbins=200,\n",
    ")\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_yaxes(title_text=\"Number of Latents\")\n",
    "\n",
    "# Update x-axis ticks\n",
    "fig.update_xaxes(\n",
    "    tickvals=[0, 0.25, 0.5, 0.75, 1.0],\n",
    "    ticktext=['0', '0.25', '0.5', '0.75', '1.0']\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c4eeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_latent_mask = (relative_norms < 0.7) & (relative_norms > 0.3)\n",
    "shared_latent_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a328be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sims = (cross_coder.W_dec[:, 0, :] * cross_coder.W_dec[:, 1, :]).sum(dim=-1) / (cross_coder.W_dec[:, 0, :].norm(dim=-1) * cross_coder.W_dec[:, 1, :].norm(dim=-1))\n",
    "cosine_sims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b24508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    cosine_sims[shared_latent_mask].to(torch.float32).detach().cpu().numpy(),\n",
    "    #title=\"Cosine similarity of decoder vectors between models\",\n",
    "    log_y=True,  # Sets the y-axis to log scale\n",
    "    range_x=[-1, 1],  # Sets the x-axis range from -1 to 1\n",
    "    nbins=100,  # Adjust this value to change the number of bins\n",
    "    labels={\"value\": \"Cosine similarity of decoder vectors between models\"}\n",
    ")\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_yaxes(title_text=\"Number of Latents (log scale)\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e854a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "folded_cross_coder = copy.deepcopy(cross_coder)\n",
    "\n",
    "base_estimated_scaling_factor = 27.489933013916016\n",
    "chat_estimated_scaling_factor = 27.12582778930664\n",
    "\n",
    "def fold_activation_scaling_factor(cross_coder, base_scaling_factor, chat_scaling_factor):\n",
    "    cross_coder.W_enc.data[0, :, :] = cross_coder.W_enc.data[0, :, :] * base_scaling_factor\n",
    "    cross_coder.W_enc.data[1, :, :] = cross_coder.W_enc.data[1, :, :] * chat_scaling_factor\n",
    "\n",
    "    # cross_coder.W_dec.data[:, 0, :] = cross_coder.W_dec.data[:, 0, :] / base_scaling_factor\n",
    "    # cross_coder.W_dec.data[:, 1, :] = cross_coder.W_dec.data[:, 1, :] / chat_scaling_factor\n",
    "\n",
    "    # cross_coder.b_dec.data[0, :] = cross_coder.b_dec.data[0, :] / base_scaling_factor\n",
    "    # cross_coder.b_dec.data[1, :] = cross_coder.b_dec.data[1, :] / chat_scaling_factor\n",
    "    return cross_coder\n",
    "\n",
    "folded_cross_coder = fold_activation_scaling_factor(folded_cross_coder, base_estimated_scaling_factor, chat_estimated_scaling_factor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56fc95",
   "metadata": {},
   "source": [
    "# Generating latent dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f10cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/liuhaozhe6788/crosscoder_vis.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b453ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crosscoder_vis.model_fns import CrossCoderConfig, CrossCoder_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cfg = CrossCoderConfig(d_in=base_model.config.hidden_size, d_hidden=cross_coder.cfg[\"dict_size\"], apply_b_dec_to_input=False)\n",
    "sae_vis_cross_coder = CrossCoder_vis(encoder_cfg)\n",
    "sae_vis_cross_coder.load_state_dict(folded_cross_coder.state_dict())\n",
    "sae_vis_cross_coder = sae_vis_cross_coder.to(\"cuda:0\")\n",
    "sae_vis_cross_coder = sae_vis_cross_coder.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063007a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_idx = [2325,12698,15]\n",
    "sae_vis_config = SaeVisConfig(\n",
    "    hook_layer = 16,\n",
    "    features = test_feature_idx,\n",
    "    verbose = True,\n",
    "    minibatch_size_texts=1,\n",
    "    minibatch_size_features=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9970e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crosscoder_vis.data_storing_fns import SaeVisData\n",
    "crosscoder_vis_data = SaeVisData.create(\n",
    "    encoder = sae_vis_cross_coder,\n",
    "    encoder_B = None,\n",
    "    model_A = base_model,\n",
    "    model_B = chat_model,\n",
    "    texts = all_texts[:128], # in practice, better to use more data\n",
    "    cfg = sae_vis_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"_feature_vis_demo.html\"\n",
    "crosscoder_vis_data.save_feature_centric_vis(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin_ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
